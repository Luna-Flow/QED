#set page(paper: "a4", margin: (x: 2.4cm, y: 2.2cm))
#set par(justify: true, leading: 0.62em)
#set text(size: 10.5pt)

#let info-color = rgb("#1d4ed8")
#let warning-color = rgb("#ca8a04")
#let critical-color = rgb("#b91c1c")

#let level-color(level) = {
  if level == "info" {
    info-color
  } else if level == "warning" {
    warning-color
  } else {
    critical-color
  }
}

#let keyblock(level, title, body) = {
  let color = level-color(level)
  rect(
    inset: 10pt,
    radius: 5pt,
    stroke: 0.5pt + color,
    fill: color.lighten(86%),
    [
      #text(fill: color)[#title]
      #v(0.35em)
      #body
    ],
  )
}

#align(center)[
  #text(size: 16pt, weight: "bold")[A Formal Mathematical Specification for QED]
  #linebreak()
  #text(size: 11pt)[A Minimal LCF-Style HOL Kernel in MoonBit]
]

#v(1.2em)

= Abstract

QED is an interactive theorem prover in MoonBit, designed around an LCF-style trusted kernel and a higher-order logic foundation. This document gives a formal, implementation-aware specification of its core theory. The presentation starts from first principles: signatures, type formation, term formation, typing judgments, substitution laws, theorem objects, and primitive inference rules. The objective is to make the trust model and proof discipline explicit enough that a reader can understand the logic of the system without reading source code.

#v(0.8em)
#keyblock("info", [Reading Guide], [
  The document is intentionally ordered from basic theory to derived engineering consequences. A reader should be able to stop after the foundational sections and still obtain a coherent understanding of the QED kernel.
])

#set heading(numbering: "1.")

= Motivation and Design Goal

The central engineering goal of QED is to separate trusted reasoning from untrusted proof search. In an LCF architecture, theorem creation is restricted to a very small set of primitive kernel operations. Everything else, including automation and tactics, is merely a theorem-producing program that calls those primitives.

This architecture has two consequences:

1. Correctness is reduced to the soundness of a small kernel.
2. Rich user tooling can evolve without expanding the trusted code base.

The mathematical role of this document is to state the object language and inference rules precisely enough to support both consequences.

= Foundational Theory

== Signatures and Symbols

Let $Sigma_t$ be a type-constructor signature. Each constructor $k in Sigma_t$ has a natural-number arity $a(k) in NN$.

Let $Sigma_c$ be a term-constant signature. Each constant $c in Sigma_c$ is assigned a simple type.

QED reserves two distinguished type constructors:

- $"bool"$ with arity $0$.
- $"fun"$ with arity $2$.

These are sufficient to define simply typed lambda terms with boolean propositions.

== Type Grammar

Types are generated by the grammar
$
  tau ::= alpha | k(tau_1, ..., tau_n)
$
where $alpha$ ranges over type variables and $k in Sigma_t$ with $a(k) = n$.

In implementation terms, QED uses:

- `TyVal(name)` for type variables.
- `TyApp(tycon, args)` for constructor application.

This representation is syntax-directed and supports recursive operations such as type substitution and constructor decomposition.

== Term Grammar

Terms are generated by
$
  t ::= x : tau | c : tau | t_1 t_2 | λ (x : tau). t
$
where $x$ is a variable symbol and $c$ is a constant symbol.

In implementation terms, QED uses:

- `Var(name, tau)`
- `Const(name, tau)`
- `Comb(f, x)`
- `Abs(x, t)`

The abstraction constructor is intended to bind occurrences of the variable component of `x` in `t`.

#keyblock("warning", [Binding and Capture], [
  Any substitution algorithm used by the kernel must be capture-avoiding. This is not a convenience detail: it is a semantic requirement for soundness.
])

= Typing Judgments

The type system is syntax-directed and is presented as a judgment of the form
$
  Gamma tack.r t : tau
$
where $Gamma$ is a typing context for free variables.

The intended rules are the standard STLC-style rules over simple types:

$
  (" "(x : tau) in Gamma" ") / (Gamma tack.r x : tau)
$

$
  (" "Sigma_c(c) = tau" ") / (Gamma tack.r c : tau)
$

$
  (" "Gamma tack.r f : "fun"(tau_1, tau_2) and Gamma tack.r x : tau_1" ")
  /
  (Gamma tack.r f x : tau_2)
$

$
  (Gamma, x : tau_1 tack.r t : tau_2)
  /
  (" "Gamma tack.r λ (x : tau_1). t : "fun"(tau_1, tau_2)" ")
$

The implementation-level helper `type_of(t)` is expected to agree with this judgment for well-formed terms.

= Substitution and Alpha-Equivalence

== Type Substitution

Type substitution is a mapping `theta : type_variable -> hol_type` that extends structurally to types and terms.

For a type variable $alpha$,

- $theta(alpha)$ if defined,
- otherwise $alpha$.

For type application $k(tau_1, ..., tau_n)$,

- apply $theta$ recursively to each argument.

== Term Substitution

Term substitution is a finite map from variables to terms. It must satisfy two constraints:

1. Type preservation: replacement terms match the declared type of replaced variables.
2. Capture avoidance: bound variables may require renaming before substitution under abstraction.

== Alpha-Equivalence

Alpha-equivalence, written $t_1 equiv_alpha t_2$, identifies terms up to systematic renaming of bound variables. It is required by multiple kernel operations, including theorem transitivity-style checks where structural syntax should not distinguish alpha-variants.

= Theorem Object and Trust Boundary

A theorem is represented mathematically as a sequent
$
  Gamma_p tack.r p
$
with $p$ a boolean term and $Gamma_p$ a finite set of boolean assumptions.

The trusted boundary condition is:

- external modules cannot directly construct theorem values,
- theorem values are produced only by primitive kernel inference functions.

This boundary is the core LCF invariant.

#keyblock("critical", [Kernel Integrity Condition], [
  If external code can fabricate theorem values, the entire soundness argument collapses, regardless of how correct individual inference rules appear.
])

= Primitive Inference Rules

QED follows a HOL Light style primitive interface:

`REFL`, `ASSUME`, `TRANS`, `MK_COMB`, `ABS`, `BETA`, `EQ_MP`, `DEDUCT_ANTISYM_RULE`, `INST_TYPE`, `INST`.

Each primitive rule must be specified by:

1. Input theorem and term constraints.
2. Side conditions (typing, freeness, alpha-matching, etc.).
3. Output sequent.
4. Failure condition classification.

For example, selected rules can be presented in antecedent style:

- `REFL`: for any term $t$, conclude $tack.r t = t$.
- `ASSUME`: for any boolean proposition $p$, conclude $p tack.r p$.

$ 
  (" "A_p tack.r s = t and B_p tack.r t = u" ")
  /
  (A_p union B_p tack.r s = u)
$

$ 
  (" "A_p tack.r p = q and B_p tack.r p" ")
  /
  (A_p union B_p tack.r q)
$

Detailed formal side conditions are maintained in parallel with implementation updates.

== Rule Schema: `REFL`

Input:

- a well-formed term $t$.

Output:

- theorem $tack.r t = t$.

Side conditions:

1. $t$ must be typable.
2. equality constructor must be formed at the type of $t$.

Failure clauses:

1. malformed term input;
2. type construction failure in equality formation.

Antecedent form:
$
  (" "Gamma tack.r t : T" ") / (tack.r t = t)
$

== Rule Schema: `ASSUME`

Input:

- a proposition term $p$.

Output:

- theorem $p tack.r p$.

Side conditions:

1. $p$ must have type $"bool"$.
2. assumption set representation must admit $p$.

Failure clauses:

1. non-boolean proposition;
2. invalid assumption-set insertion.

Antecedent form:
$
  (" "Gamma_p tack.r p : "bool"" ") / (p tack.r p)
$

== Rule Schema: `TRANS`

Input:

- theorem $A_p tack.r s = t$;
- theorem $B_p tack.r t = u$.

Output:

- theorem $A_p union B_p tack.r s = u$.

Side conditions:

1. both conclusions must be equalities;
2. the middle terms must match up to alpha-equivalence and type consistency.

Failure clauses:

1. non-equality conclusion in either premise theorem;
2. middle-term mismatch;
3. type inconsistency in chained equality.

Antecedent form:
$
  (" "A_p tack.r s = t and B_p tack.r t = u" ")
  /
  (A_p union B_p tack.r s = u)
$

== Rule Schema: `MK_COMB`

Input:

- theorem $A_p tack.r f = g$;
- theorem $B_p tack.r x = y$.

Output:

- theorem $A_p union B_p tack.r f x = g y$.

Side conditions:

1. both premise conclusions must be equalities;
2. $f$ and $g$ must have function type with argument type matching $x$ and $y$;
3. codomain types of $f$ and $g$ must coincide.

Failure clauses:

1. non-equality premise theorem;
2. function-domain mismatch for application;
3. codomain inconsistency across the two function sides.

Antecedent form:
$
  (" "A_p tack.r f = g and B_p tack.r x = y" ")
  /
  (A_p union B_p tack.r f x = g y)
$

== Rule Schema: `ABS`

Input:

- variable term $x$;
- theorem $A_p tack.r s = t$.

Output:

- theorem $A_p tack.r λ (x : tau). s = λ (x : tau). t$.

Side conditions:

1. $x$ must be a variable term;
2. premise conclusion must be an equality;
3. $x$ must not occur free in assumptions $A_p$.

Failure clauses:

1. non-variable abstraction binder;
2. non-equality premise theorem;
3. free-variable violation in assumption set.

Antecedent form:
$
  (A_p tack.r s = t)
  /
  (" "A_p tack.r λ (x : tau). s = λ (x : tau). t" ")
$

== Rule Schema: `BETA`

Input:

- a beta-redex term of shape $(λ (x : tau). s) x$.

Output:

- theorem $tack.r ((λ (x : tau). s) x) = s$.

Side conditions:

1. the argument term must match the binder variable;
2. the redex must be well-typed.

Failure clauses:

1. input is not a beta-redex of the required shape;
2. binder and argument mismatch;
3. type inconsistency in redex construction.

Antecedent form:
$
  (" "t = (λ (x : tau). s) x" ")
  /
  (tack.r t = s)
$

== Rule Schema: `EQ_MP`

Input:

- theorem $A_p tack.r p = q$;
- theorem $B_p tack.r p$.

Output:

- theorem $A_p union B_p tack.r q$.

Side conditions:

1. first premise must conclude an equality proposition;
2. left side of equality must match the second premise conclusion up to alpha-equivalence;
3. all involved terms must be boolean propositions.

Failure clauses:

1. first premise is not an equality theorem;
2. proposition mismatch between equality lhs and premise theorem;
3. non-boolean proposition in premises.

Antecedent form:
$
  (" "A_p tack.r p = q and B_p tack.r p" ")
  /
  (A_p union B_p tack.r q)
$

= Soundness Strategy

The project-level soundness story is divided into three obligations.

1. Rule-level preservation: every primitive rule preserves semantic validity.
2. Interface safety: only primitive rules can introduce theorem values.
3. Derivation closure: any finite derivation tree built from primitive rules is sound.

This decomposition is practical: it aligns the formal argument with module boundaries and test responsibilities.

= Engineering Correspondence

The formal clauses above map to implementation modules as follows.

- `src/kernel/types.mbt`: type constructors, decomposers, predicates, and type-level operators.
- `src/kernel/terms.mbt`: term constructors, decomposers, typing helper, and term-level operators.
- `src/kernel/thm.mbt`: theorem abstraction and primitive rule implementation.

A development task is complete only when the mathematical clause and its implementation clause are both updated.

= Documentation Roadmap

This document is a living formal artifact. The target final version includes:

1. full rule-by-rule formalization of all primitive inference rules,
2. explicit substitution lemmas and alpha-equivalence lemmas,
3. a consistency assumptions section,
4. an interface theorem connecting kernel and tactic layers,
5. a revision log linking formal clauses to commit history.

#keyblock("info", [Current Status], [
  The current manuscript is a foundational draft emphasizing theory and system principles. Subsequent revisions will increase proof detail and rule-level formal completeness.
])
