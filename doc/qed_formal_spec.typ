#set page(paper: "a4", margin: (x: 2.4cm, y: 2.2cm))
#set par(justify: true, leading: 0.62em)
#set text(size: 10.5pt)

#let info-color = rgb("#1d4ed8")
#let warning-color = rgb("#ca8a04")
#let critical-color = rgb("#b91c1c")

#let level-color(level) = {
  if level == "info" {
    info-color
  } else if level == "warning" {
    warning-color
  } else {
    critical-color
  }
}

#let keyblock(level, title, body) = {
  let color = level-color(level)
  rect(
    inset: 10pt,
    radius: 5pt,
    stroke: 0.5pt + color,
    fill: color.lighten(86%),
    [
      #text(fill: color)[#title]
      #v(0.35em)
      #body
    ],
  )
}

#align(center)[
  #text(size: 16pt, weight: "bold")[A Formal Mathematical Specification for QED]
  #linebreak()
  #text(size: 11pt)[A Minimal LCF-Style HOL Kernel in MoonBit]
]

#v(1.2em)

= Abstract

QED is an interactive theorem prover in MoonBit, designed around an LCF-style trusted kernel and a higher-order logic foundation. This document gives a formal, implementation-aware specification of its core theory. The presentation starts from first principles: signatures, type formation, term formation, typing judgments, substitution laws, theorem objects, and primitive inference rules. The objective is to make the trust model and proof discipline explicit enough that a reader can understand the logic of the system without reading source code.

#v(0.8em)
#keyblock("info", [Reading Guide], [
  The document is intentionally ordered from basic theory to derived engineering consequences. A reader should be able to stop after the foundational sections and still obtain a coherent understanding of the QED kernel.
])

#set heading(numbering: "1.")

= Motivation and Design Goal

The central engineering goal of QED is to separate trusted reasoning from untrusted proof search. In an LCF architecture, theorem creation is restricted to a very small set of primitive kernel operations. Everything else, including automation and tactics, is merely a theorem-producing program that calls those primitives.

This architecture has two consequences:

1. Correctness is reduced to the soundness of a small kernel.
2. Rich user tooling can evolve without expanding the trusted code base.

The mathematical role of this document is to state the object language and inference rules precisely enough to support both consequences.

= Foundational Theory

== Signatures and Symbols

Let $Sigma_t$ be a type-constructor signature. Each constructor $k in Sigma_t$ has a natural-number arity $a(k) in NN$.

Let $Sigma_c$ be a term-constant signature. Each constant $c in Sigma_c$ is assigned a simple type.

QED reserves two distinguished type constructors:

- $"bool"$ with arity $0$.
- $"fun"$ with arity $2$.

These are sufficient to define simply typed lambda terms with boolean propositions.

== Type Grammar

Types are generated by the grammar
$
  tau ::= alpha | k(tau_1, ..., tau_n)
$
where $alpha$ ranges over type variables and $k in Sigma_t$ with $a(k) = n$.

In implementation terms, QED uses:

- `TyVal(name)` for type variables.
- `TyApp(tycon, args)` for constructor application.

This representation is syntax-directed and supports recursive operations such as type substitution and constructor decomposition.

== Term Grammar

Terms are generated by
$
  t ::= x : tau | c : tau | t_1 t_2 | λ (x : tau). t
$
where $x$ is a variable symbol and $c$ is a constant symbol.

In implementation terms, QED uses:

- `Var(name, tau)`
- `Const(name, tau)`
- `Comb(f, x)`
- `Abs(x, t)`

The abstraction constructor is intended to bind occurrences of the variable component of `x` in `t`.

#keyblock("warning", [Binding and Capture], [
  Any substitution algorithm used by the kernel must be capture-avoiding. This is not a convenience detail: it is a semantic requirement for soundness.
])

= Typing Judgments

The type system is syntax-directed and is presented as a judgment of the form
$
  Gamma ⊢ t : tau
$
where $Gamma$ is a typing context for free variables.

The intended rules are the standard STLC-style rules over simple types:

$
  (" "(x : tau) in Gamma" ") / (Gamma ⊢ x : tau)
$

$
  (" "Sigma_c(c) = tau" ") / (Gamma ⊢ c : tau)
$

$
  (" "Gamma ⊢ f : "fun"(tau_1, tau_2) and Gamma ⊢ x : tau_1" ")
  /
  (Gamma ⊢ f x : tau_2)
$

$
  (Gamma, x : tau_1 ⊢ t : tau_2)
  /
  (" "Gamma ⊢ λ (x : tau_1). t : "fun"(tau_1, tau_2)" ")
$

The implementation-level helper `type_of(t)` is expected to agree with this judgment for well-formed terms.

= Substitution and Alpha-Equivalence

== Type Substitution

Type substitution is a mapping `theta : type_variable -> hol_type` that extends structurally to types and terms.

For a type variable $alpha$,

- $theta(alpha)$ if defined,
- otherwise $alpha$.

For type application $k(tau_1, ..., tau_n)$,

- apply $theta$ recursively to each argument.

== Term Substitution

Term substitution is a finite map from variables to terms. It must satisfy two constraints:

1. Type preservation: replacement terms match the declared type of replaced variables.
2. Capture avoidance: bound variables may require renaming before substitution under abstraction.

== Alpha-Equivalence

Alpha-equivalence, written $t_1 equiv_alpha t_2$, identifies terms up to systematic renaming of bound variables. It is required by multiple kernel operations, including theorem transitivity-style checks where structural syntax should not distinguish alpha-variants.

= Theorem Object and Trust Boundary

A theorem is represented mathematically as a sequent
$
  Gamma ⊢ p
$
with $p$ a boolean term and $Gamma$ a finite set of boolean assumptions.

The trusted boundary condition is:

- external modules cannot directly construct theorem values,
- theorem values are produced only by primitive kernel inference functions.

This boundary is the core LCF invariant.

#keyblock("critical", [Kernel Integrity Condition], [
  If external code can fabricate theorem values, the entire soundness argument collapses, regardless of how correct individual inference rules appear.
])

= Primitive Inference Rules

QED follows a HOL Light style primitive interface:

`REFL`, `ASSUME`, `TRANS`, `MK_COMB`, `ABS`, `BETA`, `EQ_MP`, `DEDUCT_ANTISYM_RULE`, `INST_TYPE`, `INST`.

Each primitive rule must be specified by:

1. Input theorem and term constraints.
2. Side conditions (typing, freeness, alpha-matching, etc.).
3. Output sequent.
4. Failure condition classification.

For example, selected rules can be presented in antecedent style:

- `REFL`: for any term $t$, conclude $⊢ t = t$.
- `ASSUME`: for any boolean proposition $p$, conclude $p ⊢ p$.

$ 
  (" "A ⊢ s = t and B ⊢ t = u" ")
  /
  (A union B ⊢ s = u)
$

$ 
  (" "A ⊢ p = q and B ⊢ p" ")
  /
  (A union B ⊢ q)
$

Detailed formal side conditions are maintained in parallel with implementation updates.

== Rule Schema: `REFL`

Input:

- a well-formed term `t`.

Output:

- theorem `⊢ t = t`.

Side conditions:

1. `t` must be typable.
2. equality constructor must be formed at the type of `t`.

Failure clauses:

1. malformed term input;
2. type construction failure in equality formation.

== Rule Schema: `ASSUME`

Input:

- a proposition term `p`.

Output:

- theorem `p ⊢ p`.

Side conditions:

1. `p` must have type `"bool"`.
2. assumption set representation must admit `p`.

Failure clauses:

1. non-boolean proposition;
2. invalid assumption-set insertion.

== Rule Schema: `TRANS`

Input:

- theorem `A ⊢ s = t`;
- theorem `B ⊢ t = u`.

Output:

- theorem `A union B ⊢ s = u`.

Side conditions:

1. both conclusions must be equalities;
2. the middle terms must match up to alpha-equivalence and type consistency.

Failure clauses:

1. non-equality conclusion in either premise theorem;
2. middle-term mismatch;
3. type inconsistency in chained equality.

== Rule Schema: `MK_COMB`

Input:

- theorem `A ⊢ f = g`;
- theorem `B ⊢ x = y`.

Output:

- theorem `A union B ⊢ f x = g y`.

Side conditions:

1. both premise conclusions must be equalities;
2. `f` and `g` must have function type with argument type matching `x` and `y`;
3. codomain types of `f` and `g` must coincide.

Failure clauses:

1. non-equality premise theorem;
2. function-domain mismatch for application;
3. codomain inconsistency across the two function sides.

== Rule Schema: `ABS`

Input:

- variable term `x`;
- theorem `A ⊢ s = t`.

Output:

- theorem `A ⊢ λ (x : tau). s = λ (x : tau). t`.

Side conditions:

1. `x` must be a variable term;
2. premise conclusion must be an equality;
3. `x` must not occur free in assumptions `A`.

Failure clauses:

1. non-variable abstraction binder;
2. non-equality premise theorem;
3. free-variable violation in assumption set.

= Soundness Strategy

The project-level soundness story is divided into three obligations.

1. Rule-level preservation: every primitive rule preserves semantic validity.
2. Interface safety: only primitive rules can introduce theorem values.
3. Derivation closure: any finite derivation tree built from primitive rules is sound.

This decomposition is practical: it aligns the formal argument with module boundaries and test responsibilities.

= Engineering Correspondence

The formal clauses above map to implementation modules as follows.

- `src/kernel/types.mbt`: type constructors, decomposers, predicates, and type-level operators.
- `src/kernel/terms.mbt`: term constructors, decomposers, typing helper, and term-level operators.
- `src/kernel/thm.mbt`: theorem abstraction and primitive rule implementation.

A development task is complete only when the mathematical clause and its implementation clause are both updated.

= Documentation Roadmap

This document is a living formal artifact. The target final version includes:

1. full rule-by-rule formalization of all primitive inference rules,
2. explicit substitution lemmas and alpha-equivalence lemmas,
3. a consistency assumptions section,
4. an interface theorem connecting kernel and tactic layers,
5. a revision log linking formal clauses to commit history.

#keyblock("info", [Current Status], [
  The current manuscript is a foundational draft emphasizing theory and system principles. Subsequent revisions will increase proof detail and rule-level formal completeness.
])
